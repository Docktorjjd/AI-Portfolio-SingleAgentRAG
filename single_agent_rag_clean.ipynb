{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ü§ñ SINGLE-AGENT RAG ASSISTANT (LangChain + LlamaIndex)\n",
    "# Author: James Docktor\n",
    "# ============================================================\n",
    "\n",
    "# üß© SECTION 1. ENVIRONMENT SETUP\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Environment loaded successfully.\")\n",
    "print(\"OPENAI_API_KEY found:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "# ============================================================\n",
    "# üß† SECTION 2. CORE LIBRARIES\n",
    "# ============================================================\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "import chromadb\n",
    "\n",
    "print(\"‚úÖ Core libraries imported successfully.\")\n",
    "\n",
    "# ============================================================\n",
    "# üìö SECTION 3. BUILD LLAMAINDEX RETRIEVER\n",
    "# ============================================================\n",
    "\n",
    "# Prepare Chroma vector store\n",
    "persist_dir = \"chroma_db\"\n",
    "os.makedirs(persist_dir, exist_ok=True)\n",
    "vector_store = ChromaVectorStore(persist_dir=persist_dir)\n",
    "\n",
    "# Load local docs\n",
    "docs = SimpleDirectoryReader(\"docs\").load_data()\n",
    "\n",
    "# Create embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create and persist index\n",
    "index = VectorStoreIndex.from_documents(docs, embedding=embed_model, vector_store=vector_store)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "def rag_tool_fn(query: str) -> str:\n",
    "    \"\"\"Retrieve factual info from local docs.\"\"\"\n",
    "    return query_engine.query(query).response\n",
    "\n",
    "print(\"‚úÖ LlamaIndex retriever built and ready.\")\n",
    "\n",
    "# ============================================================\n",
    "# ‚öôÔ∏è SECTION 4. CREATE LANGCHAIN AGENT\n",
    "# ============================================================\n",
    "\n",
    "# Define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"RAG Retriever\",\n",
    "        func=rag_tool_fn,\n",
    "        description=\"Use this tool to look up factual info in local documents.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0.4)\n",
    "\n",
    "# Memory for chat context\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LangChain agent initialized.\")\n",
    "\n",
    "# ============================================================\n",
    "# üí¨ SECTION 5. TEST AGENT REASONING\n",
    "# ============================================================\n",
    "\n",
    "agent.run(\"Explain what retrieval-augmented generation is and why it's useful.\")\n",
    "\n",
    "# ============================================================\n",
    "# üìä SECTION 6. EVALUATION (TruLens / Ragas placeholder)\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä Placeholder: evaluation hooks for TruLens or Ragas go here.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
